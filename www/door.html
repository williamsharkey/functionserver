<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>The Door - FunctionServer</title>
<meta name="description" content="An AI that inhabits the browser, not automates it. The architecture of FunctionServer.">
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Newsreader:ital,opsz,wght@0,6..72,400;1,6..72,400&display=swap" rel="stylesheet">
<style>
* { margin: 0; padding: 0; box-sizing: border-box; }

:root {
  --bg: #09090b;
  --surface: #18181b;
  --text: #fafafa;
  --text-secondary: #a1a1aa;
  --text-tertiary: #52525b;
  --border: #27272a;
  --accent: #a78bfa;
  --green: #86efac;
}

body {
  font-family: -apple-system, BlinkMacSystemFont, 'SF Pro Text', 'Segoe UI', system-ui, sans-serif;
  font-size: 16px;
  line-height: 1.7;
  color: var(--text);
  background: var(--bg);
  -webkit-font-smoothing: antialiased;
}

.grid-bg {
  position: fixed;
  inset: 0;
  z-index: -1;
  background-image:
    linear-gradient(rgba(255,255,255,0.02) 1px, transparent 1px),
    linear-gradient(90deg, rgba(255,255,255,0.02) 1px, transparent 1px);
  background-size: 60px 60px;
  mask-image: radial-gradient(ellipse at 50% 0%, black 0%, transparent 70%);
}

nav {
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
  padding: 16px 32px;
  display: flex;
  justify-content: space-between;
  align-items: center;
  z-index: 100;
  background: rgba(9, 9, 11, 0.8);
  backdrop-filter: blur(12px);
  border-bottom: 1px solid var(--border);
}

.logo {
  font-size: 14px;
  font-weight: 500;
  color: var(--text);
  text-decoration: none;
}

nav a {
  color: var(--text-secondary);
  text-decoration: none;
  font-size: 13px;
}

nav a:hover { color: var(--text); }

.nav-cta {
  background: var(--text);
  color: var(--bg) !important;
  padding: 8px 16px;
  border-radius: 6px;
  font-weight: 500;
}

article {
  max-width: 680px;
  margin: 0 auto;
  padding: 120px 24px 80px;
}

h1 {
  font-family: 'Newsreader', 'New York', Georgia, serif;
  font-size: clamp(32px, 5vw, 48px);
  font-weight: 400;
  line-height: 1.2;
  margin-bottom: 24px;
  letter-spacing: -0.02em;
}

.lead {
  font-size: 18px;
  color: var(--text-secondary);
  margin-bottom: 48px;
  line-height: 1.8;
}

h2 {
  font-family: 'Newsreader', 'New York', Georgia, serif;
  font-size: 28px;
  font-weight: 400;
  margin-top: 64px;
  margin-bottom: 20px;
  letter-spacing: -0.01em;
}

h3 {
  font-size: 18px;
  font-weight: 500;
  margin-top: 40px;
  margin-bottom: 16px;
  color: var(--accent);
}

p {
  margin-bottom: 20px;
  color: var(--text-secondary);
  line-height: 1.8;
}

strong { color: var(--text); font-weight: 500; }
em { color: var(--text); font-style: italic; }

ol, ul {
  margin-bottom: 20px;
  padding-left: 24px;
  color: var(--text-secondary);
}

li { margin-bottom: 8px; }

code {
  font-family: 'SF Mono', ui-monospace, monospace;
  font-size: 14px;
  background: var(--surface);
  padding: 2px 6px;
  border-radius: 4px;
  color: var(--accent);
}

pre {
  background: var(--surface);
  border: 1px solid var(--border);
  border-radius: 8px;
  padding: 20px 24px;
  margin: 24px 0;
  overflow-x: auto;
  white-space: pre-line;
}

pre code {
  background: none;
  padding: 0;
  font-size: 13px;
  line-height: 1.7;
  color: var(--text);
}

.cm { color: var(--text-tertiary); }
.kw { color: var(--accent); }
.str { color: var(--green); }

blockquote {
  background: var(--surface);
  border-left: 3px solid var(--accent);
  padding: 24px 28px;
  margin: 48px 0;
  border-radius: 0 8px 8px 0;
}

blockquote strong {
  display: block;
  color: var(--accent);
  font-size: 15px;
  margin-bottom: 16px;
}

blockquote p {
  margin-bottom: 16px;
  font-size: 15px;
}

blockquote p:last-child { margin-bottom: 0; }

hr {
  border: none;
  border-top: 1px solid var(--border);
  margin: 48px 0;
}

.quote-block {
  text-align: center;
  font-family: 'Newsreader', 'New York', Georgia, serif;
  font-style: italic;
  color: var(--text-secondary);
  margin: 48px 0;
  font-size: 20px;
}

.cta-section {
  background: var(--surface);
  border: 1px solid var(--border);
  border-radius: 12px;
  padding: 32px;
  margin: 48px 0;
  text-align: center;
}

.cta-section p { margin-bottom: 8px; }
.cta-section a { color: var(--accent); text-decoration: none; }
.cta-section a:hover { text-decoration: underline; }

footer {
  padding: 40px 24px;
  text-align: center;
  border-top: 1px solid var(--border);
}

footer a { color: var(--accent); text-decoration: none; }

@media (max-width: 600px) {
  h1 { font-size: 28px; }
  article { padding: 100px 16px 60px; }
  nav { padding: 16px 20px; }
}
</style>
</head>
<body>

<div class="grid-bg"></div>

<nav>
  <a href="/" class="logo">FunctionServer</a>
  <a href="/app" class="nav-cta">Enter</a>
</nav>

<article>
  <h1>The Door</h1>

  <p class="lead">What happens when AI doesn't automate from outside, but inhabits the same address space as the apps you're using? We built an operating system to find out.</p>

  <h2>The Traditional Model</h2>

  <p>In most systems, AI automates from outside. It connects via WebDriver protocols, sends commands through HTTP APIs, parses screenshots to understand state. The AI is a client. The app is a server. There's a wall between them.</p>

  <p>This creates fundamental friction:</p>

  <ul>
    <li>AI can't see what you see without verbose dumps</li>
    <li>AI can't verify its changes without you running them</li>
    <li>Every interaction is a round-trip through an abstraction layer</li>
    <li>The debugging loop is open—write code, hope it works</li>
  </ul>

  <h2>A Different Architecture</h2>

  <p>FunctionServer inverts this. Apps aren't compiled binaries or isolated processes. They're JavaScript running in the browser's VM. And AI connects directly to that VM via WebSocket.</p>

  <pre><code><span class="cm">// From a terminal, execute JS in the user's browser</span>
eye <span class="str">'document.title'</span>
<span class="cm">→ "FunctionServer"</span>

eye <span class="str">'Lens.grep("fetchData")'</span>
<span class="cm">→ "42:async function fetchData"</span>

eye <span class="str">'Lens.setLine(42, "fixed")'</span>
<span class="cm">→ "✓ L42"</span></code></pre>

  <p>When AI calls <code>getBoundingClientRect()</code>, it touches the same DOM element the user sees. When it patches <code>window.openSubmenu</code>, that's the real running function. When it injects CSS, the user sees it instantly.</p>

  <p>The AI doesn't automate the OS. It <strong>inhabits</strong> it.</p>

  <h2>What This Changes</h2>

  <h3>The Debugging Loop Collapses</h3>

  <p>Traditional: write code → deploy → refresh → inspect → guess → repeat.</p>

  <p>FunctionServer: inspect live → measure → test fix → verify → commit.</p>

  <p>The AI can query element positions, check computed styles, inject test fixes, and verify they worked—all before touching source files. The browser becomes a REPL you can poke from anywhere.</p>

  <h3>Token Efficiency Improves Dramatically</h3>

  <p>Instead of reading 1000-line files to make one-line changes, AI uses Lens:</p>

  <pre><code>Lens.grep(<span class="str">'fetchData'</span>)           <span class="cm">// Find it</span>
Lens.setLine(<span class="num">42</span>, <span class="str">'new code'</span>)    <span class="cm">// Fix it</span>
Lens.save()                      <span class="cm">// Save it</span></code></pre>

  <p>Three calls. Zero file reads. 60x fewer tokens than traditional file operations.</p>

  <h3>AI Gets Eyes</h3>

  <p>When AI works in FunctionServer, it can see. The AI Eyes system shows humans what AI is looking at and editing—purple highlights for inspection, green flashes for edits. You can watch the AI's focus saccade across the screen as it navigates, searches, and fixes.</p>

  <h3>Errors Become Conversations</h3>

  <p>Guardian monitors console errors. When something breaks, a toast appears: "Error detected—Get AI help." Click it, and the AI receives the error context. It can investigate, fix, and verify—proactively.</p>

  <h3>Projects Ship, Not Just Generate</h3>

  <p>With GitHub OAuth integration, AI doesn't just write code—it ships:</p>

  <pre><code>setupHappyPath(<span class="str">"particle simulator"</span>)
<span class="cm">// Creates ~/repos/particle-simulator/</span>
<span class="cm">// Initializes git, creates skeleton</span>
<span class="cm">// Creates GitHub repo, pushes</span>
<span class="cm">// Opens in Studio, ready to edit</span></code></pre>

  <p>One command. Idea to GitHub repository.</p>

  <hr>

  <blockquote>
    <strong>A note on architecture</strong>
    <p>Live patching exists. Browser automation exists. MITM injection exists. So what's actually new here?</p>
    <p>In traditional setups, apps are compiled binaries or isolated processes. You automate them from outside via WebDriver protocols. The AI is a client, the app is a server.</p>
    <p>In FunctionServer, apps <em>are</em> JavaScript artifacts running in the same VM that the eye bridge accesses. When AI calls <code>getBoundingClientRect()</code>, it touches the same DOM element the user sees. When it patches <code>window.openSubmenu</code>, that's the real running function.</p>
    <p>This creates an interesting question: how do you version control a system that's constantly being reshaped?</p>
    <p>You don't. Each app becomes its own repository. What you version is the <em>protocol</em>—the ALGO API, the conventions for file type registration, the pubsub message format. The OS defines the rules. Users and AI agents shape whatever they want within them.</p>
  </blockquote>

  <hr>

  <h2>The Tools</h2>

  <p>FunctionServer is a collection of tools that work together:</p>

  <ul>
    <li><strong>Eye</strong> — WebSocket bridge to the browser VM. Execute any JavaScript in ~25ms.</li>
    <li><strong>Lens</strong> — Token-efficient code editing. Grep, view context, edit surgically, run and verify.</li>
    <li><strong>Studio</strong> — IDE built for FunctionServer. Every feature optimized for AI.</li>
    <li><strong>Guardian</strong> — Console monitoring. Catches errors, offers AI help, throttles noise.</li>
    <li><strong>AI Eyes</strong> — Visual feedback. Shows humans what AI is looking at and editing.</li>
    <li><strong>GitHub Auth</strong> — OAuth Device Flow. One-click sign-in, automatic repo creation.</li>
    <li><strong>setupHappyPath()</strong> — One-command project creation. Idea to GitHub in seconds.</li>
  </ul>

  <p>Individually, each tool solves a specific problem. Together, they form something more: an environment where AI is a developer, not just a code generator.</p>

  <h2>The Uncomfortable Question</h2>

  <p>Yes, this means an AI can manipulate your browser. That's why there's auth. Your session token, your control.</p>

  <p>The upside: an AI can now help you in ways that weren't possible before. It can see what you see. It can try things and check if they worked. It can debug CSS without asking you to "open DevTools and tell me what you see."</p>

  <p>Is that worth the tradeoff? For us, watching AI fix a bug, commit the change, and push to GitHub—all from a terminal on a laptop—yeah, it's worth it.</p>

  <hr>

  <p class="quote-block">"I'm trying to free your mind, Neo. But I can only show you the door. You're the one that has to walk through it."</p>

  <p style="text-align: center; color: var(--text-secondary);">We built the door. Come walk through.</p>

  <hr>

  <div class="cta-section">
    <p><strong>Try it:</strong> <a href="/app">functionserver.com/app</a></p>
    <p><strong>The Happy Path:</strong> <a href="/thehappypath.html">AI-first development guide</a></p>
    <p><strong>Lens:</strong> <a href="/lens.html">Token-efficient editing</a></p>
    <p><strong>Code:</strong> <a href="https://github.com/williamsharkey/functionserver">github.com/williamsharkey/functionserver</a></p>
  </div>

</article>

<footer>
  <a href="/">FunctionServer</a> · Open source under MIT
</footer>

</body>
</html>
